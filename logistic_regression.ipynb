{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/4e/ba/ce9bd1cd4953336a0e213b29cb80bb11816f2a93de8c99f88ef0b446ad0c/scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\patri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\patri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.2 MB 3.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/9.2 MB 3.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/9.2 MB 3.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/9.2 MB 3.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/9.2 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 3.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 3.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.4/9.2 MB 3.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/9.2 MB 3.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.2 MB 3.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.2 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.2 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.5/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.2/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.5/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.1/9.2 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.9/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.3/9.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.5/9.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.6/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.2/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.4/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.8/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.2 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.8/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.3/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.5/9.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 194.6/302.2 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\patri\\Documents\\FYPCapstone\\Data\"\n",
    "\n",
    "train_df = pd.read_csv(csv_path + '\\\\training_dataset.csv')\n",
    "test_df = pd.read_csv(csv_path + '\\\\testing_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (input variables) and the target variables (impaired_1 to impaired_20)\n",
    "identifier = ['SEQN', 'func_score'] \n",
    "\n",
    "X_train = train_df.drop(identifier + [f'impaired_{i}' for i in range(1, 21)], axis=1)\n",
    "X_test = test_df.drop(identifier + [f'impaired_{i}' for i in range(1, 21)], axis=1)\n",
    "\n",
    "targets = [f'impaired_{i}' for i in range(1, 21)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using KNN imputation with K=1\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable: impaired_1\n",
      "Training AUC: 0.5915615222202437\n",
      "Testing AUC: 0.6739850427350427\n",
      "\n",
      "Target Variable: impaired_2\n",
      "Training AUC: 0.6432283074892774\n",
      "Testing AUC: 0.6368640533778149\n",
      "\n",
      "Target Variable: impaired_3\n",
      "Training AUC: 0.7327886215766379\n",
      "Testing AUC: 0.6365280289330922\n",
      "\n",
      "Target Variable: impaired_4\n",
      "Training AUC: 0.47359111476758536\n",
      "Testing AUC: 0.19590114526823382\n",
      "\n",
      "Target Variable: impaired_5\n",
      "Training AUC: 0.764334085778781\n",
      "Testing AUC: 0.6485834840265219\n",
      "\n",
      "Target Variable: impaired_6\n",
      "Training AUC: 1.0\n",
      "Testing AUC: 0.3954954954954955\n",
      "\n",
      "impaired_7 only contains one class.\n",
      "impaired_8 only contains one class.\n",
      "impaired_9 only contains one class.\n",
      "impaired_10 only contains one class.\n",
      "impaired_11 only contains one class.\n",
      "impaired_12 only contains one class.\n",
      "impaired_13 only contains one class.\n",
      "impaired_14 only contains one class.\n",
      "impaired_15 only contains one class.\n",
      "impaired_16 only contains one class.\n",
      "impaired_17 only contains one class.\n",
      "impaired_18 only contains one class.\n",
      "impaired_19 only contains one class.\n",
      "impaired_20 only contains one class.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each target variable and train a logistic regression model\n",
    "for target in targets:\n",
    "    # Prepare the data for the target variable\n",
    "    y_train = train_df[target]\n",
    "    y_test = test_df[target]\n",
    "\n",
    "    try:\n",
    "        model = LogisticRegression(penalty=None).fit(X_train, y_train)\n",
    "        train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "        test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        # Print the AUC for the current model\n",
    "        print(f\"Target Variable: {target}\")\n",
    "        print(f\"Training AUC: {train_auc}\")\n",
    "        print(f\"Testing AUC: {test_auc}\")\n",
    "        print()\n",
    "\n",
    "    except: \n",
    "        print(f\"{target} only contains one class.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
